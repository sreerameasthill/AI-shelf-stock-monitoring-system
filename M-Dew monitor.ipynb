{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72b8f07-38d4-4b98-8a58-aa704ec04fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sakha\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\sakha\\anaconda3\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sakha\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\sakha\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sakha\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sakha\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pywhatkit in c:\\users\\sakha\\anaconda3\\lib\\site-packages (5.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\sakha\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pyautogui in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pywhatkit) (0.9.54)\n",
      "Requirement already satisfied: requests in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pywhatkit) (2.32.3)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pywhatkit) (1.4.0)\n",
      "Requirement already satisfied: Flask in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pywhatkit) (3.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from Flask->pywhatkit) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->Flask->pywhatkit) (3.0.2)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pyautogui->pywhatkit) (2.0.1)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pyautogui->pywhatkit) (1.2.0)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pyautogui->pywhatkit) (1.0.1)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pyautogui->pywhatkit) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pyautogui->pywhatkit) (0.1.3)\n",
      "Requirement already satisfied: pyrect in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui->pywhatkit) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui->pywhatkit) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from requests->pywhatkit) (2025.4.26)\n",
      "Requirement already satisfied: executing in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from wikipedia->pywhatkit) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sakha\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia->pywhatkit) (2.5)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installation\n",
    "# Run this cell once to install necessary libraries\n",
    "!pip install opencv-python pillow numpy pandas scikit-learn joblib pywhatkit ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "662713b0-eccc-4f24-8010-cd3c60462f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Quick Test...\n",
      "Created dummy test image.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: Quick Test (Manual Simulation)\n",
    "# Purpose: Verify detection logic on a static image before running live.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "def quick_test_detection(image_path=None):\n",
    "    \"\"\"\n",
    "    Simulates the detection pipeline on a single image.\n",
    "    If image_path is None, creates a dummy image for demonstration.\n",
    "    \"\"\"\n",
    "    if image_path:\n",
    "        frame = cv2.imread(image_path)\n",
    "        if frame is None:\n",
    "            print(f\"Error: Could not load {image_path}\")\n",
    "            return\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        # Create a dummy image with a green rectangle and black circle\n",
    "        frame = np.ones((480, 640, 3), dtype=np.uint8) * 200\n",
    "        # Draw \"bottle\" (Green)\n",
    "        cv2.rectangle(frame, (300, 200), (360, 400), (0, 255, 0), -1)\n",
    "        # Draw \"cap\" (Black)\n",
    "        cv2.circle(frame, (330, 210), 15, (0, 0, 0), -1)\n",
    "        print(\"Created dummy test image.\")\n",
    "    # --- Detection Logic (Simplified for Test) ---\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "    # Neon Green approx range\n",
    "    lower_green = np.array([35, 100, 100])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bottle_count = 0\n",
    "    \n",
    "    debug_frame = frame.copy()\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500: # Min area\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # Cap Detection: Look in the top 30% of the bounding box\n",
    "            roi_h = int(h * 0.3)\n",
    "            roi = frame[y:y+roi_h, x:x+w]\n",
    "            gray_roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            # Check for dark regions (caps)\n",
    "            # Method: Thresholding + Contour\n",
    "            _, cap_thresh = cv2.threshold(gray_roi, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "            cap_contours, _ = cv2.findContours(cap_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            has_cap = False\n",
    "            for c_cap in cap_contours:\n",
    "                if cv2.contourArea(c_cap) > 20: # Min cap area\n",
    "                    has_cap = True\n",
    "                    break\n",
    "            \n",
    "            if has_cap:\n",
    "                bottle_count += 1\n",
    "                cv2.rectangle(debug_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                cv2.putText(debug_frame, \"Bottle\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(debug_frame, (x, y), (x+w, y+h), (255, 0, 0), 1) # Red for no cap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(debug_frame)\n",
    "    plt.title(f\"Detected: {bottle_count} Bottles\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "# Run the test\n",
    "print(\"Running Quick Test...\")\n",
    "quick_test_detection() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a07928c-ec3d-42b9-9580-79c1b25995ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. UI Widgets created.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Setup and UI Widgets\n",
    "# Purpose: Import libraries, setup folders, and create the data collection UI.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import io\n",
    "import threading\n",
    "import time\n",
    "# 1. Setup Directories and Files\n",
    "if not os.path.exists('md_images'):\n",
    "    os.makedirs('md_images')\n",
    "CSV_FILE = 'md_counts.csv'\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    df = pd.DataFrame(columns=['filename', 'count', 'timestamp'])\n",
    "    df.to_csv(CSV_FILE, index=False)\n",
    "# 2. Global Variables for UI\n",
    "stop_camera = False\n",
    "save_trigger = False\n",
    "current_frame_bgr = None\n",
    "# 3. UI Widgets\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "count_input = widgets.IntText(value=5, description='True Count:', disabled=False)\n",
    "save_button = widgets.Button(description=\"Save Training Data\", button_style='success')\n",
    "stop_button = widgets.Button(description=\"Stop Camera\", button_style='danger')\n",
    "status_label = widgets.Label(value=\"Status: Ready\")\n",
    "# 4. Event Handlers\n",
    "def on_save_clicked(b):\n",
    "    global save_trigger\n",
    "    save_trigger = True\n",
    "    status_label.value = \"Status: Saving...\"\n",
    "def on_stop_clicked(b):\n",
    "    global stop_camera\n",
    "    stop_camera = True\n",
    "    status_label.value = \"Status: Stopping...\"\n",
    "save_button.on_click(on_save_clicked)\n",
    "stop_button.on_click(on_stop_clicked)\n",
    "# Layout\n",
    "ui_box = widgets.VBox([\n",
    "    image_widget,\n",
    "    widgets.HBox([count_input, save_button, stop_button]),\n",
    "    status_label\n",
    "])\n",
    "print(\"Setup Complete. UI Widgets created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba8187fe-8828-4522-a638-bc2d8e5d7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Camera in Background Thread... Click 'Stop Camera' to finish.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2a43d2b793473eb24d129d4bc5c3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg', height='480', width='640'), HBox(children=(IntText(value=5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Thread Started.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Camera Capture & Data Collection\n",
    "# Purpose: Live webcam feed with CV detection. Collects training data.\n",
    "# TUNING PARAMETERS\n",
    "HSV_LOWER = np.array([35, 100, 100]) # Lower bound for Neon Green\n",
    "HSV_UPPER = np.array([85, 255, 255]) # Upper bound for Neon Green\n",
    "MIN_AREA = 1000                      # Min area for bottle contour\n",
    "CAP_ROI_HEIGHT_RATIO = 0.35          # Top 35% of bottle to look for cap\n",
    "CAP_INTENSITY_THRESH = 80            # Max intensity to consider \"black\"\n",
    "CAP_MIN_AREA = 50                    # Min area for a cap contour\n",
    "def run_data_collection_camera():\n",
    "    global stop_camera, save_trigger, current_frame_bgr\n",
    "    stop_camera = False\n",
    "    \n",
    "    # Open camera in the thread to avoid blocking\n",
    "    def camera_loop():\n",
    "        global stop_camera, save_trigger, current_frame_bgr\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open webcam.\")\n",
    "            return\n",
    "        print(\"Camera Thread Started.\")\n",
    "        \n",
    "        while not stop_camera:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            current_frame_bgr = frame.copy()\n",
    "            \n",
    "            # --- CV PIPELINE ---\n",
    "            # A) Color Segmentation (Neon Green)\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            mask = cv2.inRange(hsv, HSV_LOWER, HSV_UPPER)\n",
    "            \n",
    "            # Morphological ops to clean up noise\n",
    "            kernel = np.ones((5,5), np.uint8)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            detected_bottles = 0\n",
    "            \n",
    "            for cnt in contours:\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if area > MIN_AREA:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    \n",
    "                    # B) Black Cap Detection\n",
    "                    # Look only in the top portion of the bounding box\n",
    "                    roi_h = int(h * CAP_ROI_HEIGHT_RATIO)\n",
    "                    roi = frame[y:y+roi_h, x:x+w]\n",
    "                    \n",
    "                    if roi.size > 0:\n",
    "                        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                        \n",
    "                        # Threshold to find dark objects (caps)\n",
    "                        _, cap_thresh = cv2.threshold(gray_roi, CAP_INTENSITY_THRESH, 255, cv2.THRESH_BINARY_INV)\n",
    "                        \n",
    "                        # Check for cap contours\n",
    "                        cap_contours, _ = cv2.findContours(cap_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        \n",
    "                        has_cap = False\n",
    "                        for c_cap in cap_contours:\n",
    "                            if cv2.contourArea(c_cap) > CAP_MIN_AREA:\n",
    "                                has_cap = True\n",
    "                                break\n",
    "                        \n",
    "                        if has_cap:\n",
    "                            detected_bottles += 1\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, \"Dew\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+roi_h), (0, 0, 255), 1)\n",
    "                        else:\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 1)\n",
    "            # Overlay Info\n",
    "            cv2.putText(frame, f\"CV Count: {detected_bottles}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            # --- SAVE DATA ---\n",
    "            if save_trigger:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"dew_{timestamp}.jpg\"\n",
    "                filepath = os.path.join('md_images', filename)\n",
    "                \n",
    "                # Save the ORIGINAL frame (without boxes) for training\n",
    "                cv2.imwrite(filepath, current_frame_bgr)\n",
    "                \n",
    "                # Append to CSV\n",
    "                true_count = count_input.value\n",
    "                new_row = pd.DataFrame({'filename': [filename], 'count': [true_count], 'timestamp': [timestamp]})\n",
    "                new_row.to_csv(CSV_FILE, mode='a', header=False, index=False)\n",
    "                \n",
    "                # Update status safely\n",
    "                status_label.value = f\"Saved {filename} | Count: {true_count}\"\n",
    "                save_trigger = False\n",
    "                time.sleep(0.2) \n",
    "            # Update Widget\n",
    "            _, encoded_image = cv2.imencode('.jpg', frame)\n",
    "            image_widget.value = encoded_image.tobytes()\n",
    "            \n",
    "            # Sleep to limit FPS and let other threads run\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "        cap.release()\n",
    "        status_label.value = \"Camera Stopped\"\n",
    "    print(\"Starting Camera in Background Thread... Click 'Stop Camera' to finish.\")\n",
    "    display(ui_box)\n",
    "    threading.Thread(target=camera_loop).start()\n",
    "# Run the collection loop\n",
    "run_data_collection_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e23a6c3-4816-4ea3-8ae5-2ca2d5adb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting Data ---\n",
      "Total Records in CSV: 493\n",
      "Total Images in Folder: 177\n",
      "\n",
      "First 5 rows:\n",
      "                  filename  count        timestamp\n",
      "0  dew_20251215_172852.jpg      5  20251215_172852\n",
      "1  dew_20251215_172853.jpg      5  20251215_172853\n",
      "2  dew_20251215_172854.jpg      5  20251215_172854\n",
      "3  dew_20251215_172856.jpg      5  20251215_172856\n",
      "4  dew_20251215_172856.jpg      5  20251215_172856\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Quick Data Inspection\n",
    "# Purpose: Check how many images we have collected.\n",
    "import pandas as pd\n",
    "import os\n",
    "print(\"--- Inspecting Data ---\")\n",
    "if os.path.exists('md_counts.csv'):\n",
    "    try:\n",
    "        df = pd.read_csv('md_counts.csv')\n",
    "        print(f\"Total Records in CSV: {len(df)}\")\n",
    "        if len(df) > 0:\n",
    "            print(f\"Total Images in Folder: {len(os.listdir('md_images'))}\")\n",
    "            print(\"\\nFirst 5 rows:\")\n",
    "            print(df.head())\n",
    "        else:\n",
    "            print(\"CSV is empty. Please collect data in Cell 4.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "else:\n",
    "    print(\"md_counts.csv not found. Did you run Cell 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d02aae9-f2f6-49b2-8ef9-a1a4d8be402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model Training ---\n",
      "Loading data from md_counts.csv...\n",
      "Found 431 records. Processing images...\n",
      "Successfully loaded 431 valid images.\n",
      "Training on 431 samples...\n",
      "Model Trained! MAE: 0.00, Accuracy (rounded): 100.0%\n",
      "Model saved to md_count_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Robust Training Cell\n",
    "# Purpose: Train a RandomForestRegressor to predict bottle count from images.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "IMG_SIZE = 64 # Resize images to 64x64 for speed\n",
    "def train_model():\n",
    "    print(\"--- Starting Model Training ---\")\n",
    "    print(\"Loading data from md_counts.csv...\")\n",
    "    if not os.path.exists('md_counts.csv'):\n",
    "        print(\"Error: md_counts.csv not found. Run data collection first.\")\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_csv('md_counts.csv')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "        return\n",
    "        \n",
    "    if len(df) == 0:\n",
    "        print(\"Error: CSV is empty. You need to collect images in Cell 4 first!\")\n",
    "        return\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    valid_count = 0\n",
    "    \n",
    "    print(f\"Found {len(df)} records. Processing images...\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        img_path = os.path.join('md_images', row['filename'])\n",
    "        if os.path.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                # Preprocess: Resize and Flatten\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                flat_img = img.flatten() / 255.0 # Normalize\n",
    "                \n",
    "                X.append(flat_img)\n",
    "                y.append(row['count'])\n",
    "                valid_count += 1\n",
    "            else:\n",
    "                print(f\"Warning: Could not read image {img_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: Image not found {img_path}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {valid_count} valid images.\")\n",
    "    \n",
    "    if valid_count < 8:\n",
    "        print(f\"Error: Too few samples ({valid_count}). Please collect at least 8-10 images in Cell 4.\")\n",
    "        return\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"Training on {len(X)} samples...\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Model\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    preds = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rounded_preds = np.round(preds)\n",
    "    acc = accuracy_score(y_test, rounded_preds)\n",
    "    \n",
    "    print(f\"Model Trained! MAE: {mae:.2f}, Accuracy (rounded): {acc*100:.1f}%\")\n",
    "    \n",
    "    # Save Model\n",
    "    joblib.dump(model, 'md_count_model.pkl')\n",
    "    print(\"Model saved to md_count_model.pkl\")\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ef3f5c4-59f3-4f04-9b67-d90a781d8fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc5151c623641d7b663edb70bc58236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg', height='480', width='640'), VBox(children=(HBox(children=(Butto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Inference Thread...\n",
      "Attempting to open camera...\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Live Inference & Alerting\n",
    "# Purpose: Live monitoring with Lock-and-Wait alert logic.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pywhatkit\n",
    "import threading\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PHONE_NUMBER = \"+919846516116\"\n",
    "LOW_STOCK_THRESHOLD = 3\n",
    "COUNTDOWN_SECONDS = 5\n",
    "WHATSAPP_WAIT_TIME = 20        # Increased to 30s as requested to ensure WhatsApp Web loads fully\n",
    "\n",
    "# --- STATE VARIABLES ---\n",
    "stop_inference = False\n",
    "alert_sent = False\n",
    "locked_state = False\n",
    "locked_count = 0\n",
    "lock_start_time = 0\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "try:\n",
    "    model = joblib.load('md_count_model.pkl')\n",
    "    print(\"Model loaded successfully.\")\n",
    "except:\n",
    "    print(\"WARNING: Model not found. Running in CV-only mode.\")\n",
    "    model = None\n",
    "\n",
    "# --- WHATSAPP WORKER ---\n",
    "def send_whatsapp_alert():\n",
    "    print(\"\\n[Background] Triggering WhatsApp Alert...\")\n",
    "    try:\n",
    "        pywhatkit.sendwhatmsg_instantly(\n",
    "            PHONE_NUMBER, \n",
    "            \"ALERT: Mountain Dew Stock is LOW (Below 3)! Please refill. - Tuck Shop\", \n",
    "            wait_time=WHATSAPP_WAIT_TIME,\n",
    "            tab_close=True\n",
    "        )\n",
    "        print(f\"[Background] Alert Sent.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Background] Failed to send alert: {e}\")\n",
    "\n",
    "# --- UI WIDGETS ---\n",
    "inf_image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "inf_stop_button = widgets.Button(description=\"Stop Monitoring\", button_style='danger')\n",
    "inf_test_alert_btn = widgets.Button(description=\"Test WhatsApp\", button_style='warning')\n",
    "inf_status_label = widgets.Label(value=\"Status: Starting...\")\n",
    "\n",
    "# Tuning Sliders\n",
    "thresh_slider = widgets.IntSlider(value=80, min=0, max=255, description='Cap Dark Thresh:')\n",
    "area_slider = widgets.IntSlider(value=1000, min=100, max=5000, description='Min Bottle Area:')\n",
    "debug_checkbox = widgets.Checkbox(value=False, description='Show Debug Boxes')\n",
    "\n",
    "def on_inf_stop(b):\n",
    "    global stop_inference\n",
    "    stop_inference = True\n",
    "\n",
    "def on_test_alert(b):\n",
    "    threading.Thread(target=send_whatsapp_alert).start()\n",
    "\n",
    "inf_stop_button.on_click(on_inf_stop)\n",
    "inf_test_alert_btn.on_click(on_test_alert)\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    widgets.HBox([inf_stop_button, inf_test_alert_btn]),\n",
    "    widgets.HBox([thresh_slider, area_slider, debug_checkbox]),\n",
    "    inf_status_label\n",
    "])\n",
    "\n",
    "display(widgets.VBox([inf_image_widget, controls]))\n",
    "\n",
    "# --- INFERENCE LOOP ---\n",
    "def run_inference():\n",
    "    global stop_inference, alert_sent, locked_state, locked_count, lock_start_time\n",
    "    stop_inference = False\n",
    "    alert_sent = False\n",
    "    locked_state = False\n",
    "    \n",
    "    def inference_thread():\n",
    "        global stop_inference, alert_sent, locked_state, locked_count, lock_start_time\n",
    "        \n",
    "        print(\"Attempting to open camera...\")\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            inf_status_label.value = \"Error: Camera Busy\"\n",
    "            return\n",
    "            \n",
    "        inf_status_label.value = \"Status: Running\"\n",
    "        \n",
    "        while not stop_inference:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            # Draw UI Overlay placeholders\n",
    "            status_text = \"Stock OK\"\n",
    "            status_color = (0, 255, 0)\n",
    "            final_count = 0\n",
    "            \n",
    "            if locked_state:\n",
    "                # --- LOCKED STATE (Countdown) ---\n",
    "                # Don't run CV/ML. Just show the locked count.\n",
    "                final_count = locked_count\n",
    "                \n",
    "                elapsed = time.time() - lock_start_time\n",
    "                remaining = COUNTDOWN_SECONDS - elapsed\n",
    "                \n",
    "                if remaining > 0:\n",
    "                    status_text = f\"LOCKED! Sending in {remaining:.1f}s...\"\n",
    "                    status_color = (0, 165, 255) # Orange\n",
    "                else:\n",
    "                    # Time's up! Send Alert.\n",
    "                    status_text = \"SENDING ALERT & STOPPING...\"\n",
    "                    status_color = (0, 0, 255) # Red\n",
    "                    \n",
    "                    # 1. Start the alert thread\n",
    "                    threading.Thread(target=send_whatsapp_alert).start()\n",
    "                    \n",
    "                    # 2. Set flag to STOP monitoring immediately\n",
    "                    stop_inference = True\n",
    "                    \n",
    "                    # 3. Update status (though loop breaks immediately after)\n",
    "                    alert_sent = True\n",
    "                    locked_state = False\n",
    "                    \n",
    "                    # 4. Break loop explicitly to ensure no further processing\n",
    "                    break\n",
    "            \n",
    "            else:\n",
    "                # --- MONITORING STATE ---\n",
    "                # Run CV/ML logic\n",
    "                \n",
    "                # Get sliders\n",
    "                CAP_INTENSITY_THRESH = thresh_slider.value\n",
    "                MIN_AREA = area_slider.value\n",
    "                SHOW_DEBUG = debug_checkbox.value\n",
    "                \n",
    "                # 1. CV\n",
    "                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                # NOTE: HSV_LOWER and HSV_UPPER must be defined in previous cells\n",
    "                mask = cv2.inRange(hsv, HSV_LOWER, HSV_UPPER)\n",
    "                kernel = np.ones((5,5), np.uint8)\n",
    "                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "                mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                cv_count = 0\n",
    "                for cnt in contours:\n",
    "                    if cv2.contourArea(cnt) > MIN_AREA:\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        if SHOW_DEBUG: cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 1)\n",
    "                        \n",
    "                        roi_h = int(h * CAP_ROI_HEIGHT_RATIO)\n",
    "                        roi = frame[y:y+roi_h, x:x+w]\n",
    "                        if roi.size > 0:\n",
    "                            gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                            _, cap_thresh = cv2.threshold(gray_roi, CAP_INTENSITY_THRESH, 255, cv2.THRESH_BINARY_INV)\n",
    "                            cap_contours, _ = cv2.findContours(cap_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                            if any(cv2.contourArea(c) > CAP_MIN_AREA for c in cap_contours):\n",
    "                                cv_count += 1\n",
    "                                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                                cv2.putText(frame, \"Dew\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                # 2. ML\n",
    "                ml_count = 0\n",
    "                if model:\n",
    "                    try:\n",
    "                        img_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "                        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "                        flat_vec = img_rgb.flatten() / 255.0\n",
    "                        ml_count = model.predict([flat_vec])[0]\n",
    "                    except: pass\n",
    "                \n",
    "                # 3. Ensemble\n",
    "                if model:\n",
    "                    final_count = round(0.7 * ml_count + 0.3 * cv_count)\n",
    "                else:\n",
    "                    final_count = cv_count\n",
    "                \n",
    "                # 4. Check Trigger\n",
    "                if final_count < LOW_STOCK_THRESHOLD:\n",
    "                    if not alert_sent:\n",
    "                        # TRIGGER LOCK\n",
    "                        locked_state = True\n",
    "                        locked_count = final_count\n",
    "                        lock_start_time = time.time()\n",
    "                    else:\n",
    "                        status_text = \"Stock Low (Alert Sent)\"\n",
    "                        status_color = (0, 0, 255)\n",
    "                else:\n",
    "                    # Reset alert flag if stock recovers\n",
    "                    if alert_sent:\n",
    "                        alert_sent = False\n",
    "                        status_text = \"Stock Recovered\"\n",
    "            \n",
    "            # Display\n",
    "            cv2.putText(frame, f\"Final: {int(final_count)}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.5, status_color, 3)\n",
    "            cv2.putText(frame, status_text, (10, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)\n",
    "            _, encoded_image = cv2.imencode('.jpg', frame)\n",
    "            inf_image_widget.value = encoded_image.tobytes()\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        cap.release()\n",
    "        inf_status_label.value = \"Monitoring Stopped (Alert Triggered)\"\n",
    "    \n",
    "    threading.Thread(target=inference_thread).start()\n",
    "\n",
    "print(\"Starting Inference Thread...\")\n",
    "run_inference()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622c3dd-65ae-4419-a842-55f416f397d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
